---
layout: post
title:  GAN
categories: DL
tags: GAN
author: ccpocker
---

### 1.Generative adversarial Networ

##### 1.1 PipeLine and Loss function
![图1.1：GAN结构图](https://raw.githubusercontent.com/ccpocker/my_img/master/GAN-pipeline.png)


对抗生成网络的损失函数：

$L_{GAN}=V(D,G)=\mathbb{E}_{x\sim p_{data}}log(D(x))+\mathbb{E}_{z\sim p_z(z)}(log(1-D(G(z))))$

其中$\mathbb{E}_{x\sim p_{data}}log(D(x))$为判别器损失
其中$\mathbb{E}_{z\sim p_z(z)}(log(1-D(G(z))))$为生成器损失

##### 1.2 Details and Experiment

![图1.2：GAN训练过程](https://raw.githubusercontent.com/ccpocker/my_img/master/GAN-training.jpg)
- 一个简单的例子如上图1.2所示：假设在训练开始时，真实样本分布、生成样本分布以及判别模型分别是图中的黑线、绿线和蓝线。可以看出，在训练开始时，判别模型是无法很好地区分真实样本和生成样本的。
- 接下来当我们固定生成模型，而优化判别模型时，优化结果如第二幅图所示，可以看出，这个时候判别模型已经可以较好的区分生成数据和真实数据了。
- 第三步是固定判别模型，改进生成模型，试图让判别模型无法区分生成图片与真实图片，在这个过程中，可以看出由模型生成的图片分布与真实图片分布更加接近，这样的迭代不断进行，直到最终收敛，生成分布和真实分布重合。

GAN的算法实现如图1.2所示。
![图1.2：GAN算法实现](https://raw.githubusercontent.com/ccpocker/my_img/master/GAN-algorithm.png)

### 2.Conditional Generative adversarial Networ
由于原生的GAN的生成器的输入为噪声z，其生成难以控制。一个很自然的想法就是对生成器进行约束。条件对抗生成网络，通过对生成器以及判别器加入额外的标签信息，用以指导生成器的生成过程，从而实现对生成图像的控制。

##### 2.1 Pipeline and gitLoss function
![图2.1：cGAN结构图](https://raw.githubusercontent.com/ccpocker/my_img/master/cGAN-pipeline.png)

如图2.1，生成器的输入不再是单一的噪声，而且还有条件信息（如图标签，文字等），先验噪声$z$与条件信息$c$联合组成了联合隐层表征，生成器G输入的分布$p_z(z|c)$为一条件分布。同理，判别器D也同时接受额外的条件信息$c$。通过最大最小博弈，引入额外的条件信息实现对生成图像的约束控制。

条件对抗生成网络的损失函数：

$L_{cGAN}=V(D,G)=\mathbb{E}_{x\sim p_{data}}log(D(x|c))+\mathbb{E}_{z\sim p_z(z)}(log(1-D(G(z|c))))$
##### 1.2 Details and Experiment
cGAN的算法实现如图2.2所示。
![图2.2：cGAN算法实现](https://raw.githubusercontent.com/ccpocker/my_img/master/cGAN-alogrithm.png)





